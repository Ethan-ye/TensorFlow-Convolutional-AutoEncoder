{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:52:24.021811Z",
     "start_time": "2019-12-03T06:52:19.406098Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models import *\n",
    "from mnist import MNIST  # this is the MNIST data manager that provides training/testing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:53:53.696665Z",
     "start_time": "2019-12-03T06:53:53.664753Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(object):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        build the graph\n",
    "        \"\"\"\n",
    "        # place holder of input data\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])  # [#batch, img_height, img_width, #channels]\n",
    "\n",
    "        # encode\n",
    "        conv1 = Convolution2D([5, 5, 1, 32], activation=tf.nn.relu, scope='conv_1')(x)\n",
    "        pool1 = MaxPooling(kernel_shape=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', scope='pool_1')(conv1)\n",
    "        conv2 = Convolution2D([5, 5, 32, 32], activation=tf.nn.relu, scope='conv_2')(pool1)\n",
    "        pool2 = MaxPooling(kernel_shape=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', scope='pool_2')(conv2)\n",
    "        unfold = Unfold(scope='unfold')(pool2)\n",
    "        encoded = FullyConnected(20, activation=tf.nn.relu, scope='encode')(unfold)\n",
    "        # decode\n",
    "        decoded = FullyConnected(7*7*32, activation=tf.nn.relu, scope='decode')(encoded)\n",
    "        fold = Fold([-1, 7, 7, 32], scope='fold')(decoded)\n",
    "        unpool1 = UnPooling((2, 2), output_shape=tf.shape(conv2), scope='unpool_1')(fold)\n",
    "        deconv1 = DeConvolution2D([5, 5, 32, 32], output_shape=tf.shape(pool1), activation=tf.nn.relu, scope='deconv_1')(unpool1)\n",
    "        unpool2 = UnPooling((2, 2), output_shape=tf.shape(conv1), scope='unpool_2')(deconv1)\n",
    "        reconstruction = DeConvolution2D([5, 5, 1, 32], output_shape=tf.shape(x), activation=tf.nn.sigmoid, scope='deconv_2')(unpool2)\n",
    "\n",
    "        # loss function\n",
    "        loss = tf.nn.l2_loss(x - reconstruction)  # L2 loss\n",
    "\n",
    "        # training\n",
    "        training = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "        #\n",
    "        self.x = x\n",
    "        self.reconstruction = reconstruction\n",
    "        self.loss = loss\n",
    "        self.training = training\n",
    "\n",
    "    def train(self, batch_size, passes, new_training=True):\n",
    "        \"\"\"\n",
    "\n",
    "        :param batch_size:\n",
    "        :param passes:\n",
    "        :param new_training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mnist = MNIST()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # prepare session\n",
    "            if new_training:\n",
    "                saver, global_step = Model.start_new_session(sess)\n",
    "            else:\n",
    "                saver, global_step = Model.continue_previous_session(sess, ckpt_file='saver/checkpoint')\n",
    "\n",
    "            # start training\n",
    "            for step in range(1+global_step, 1+passes+global_step):\n",
    "                x, y = mnist.get_batch(batch_size)\n",
    "                self.training.run(feed_dict={self.x: x})\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    loss = self.loss.eval(feed_dict={self.x: x})\n",
    "                    print(\"pass {}, training loss {}\".format(step, loss))\n",
    "\n",
    "                if step % 1000 == 0:  # save weights\n",
    "                    saver.save(sess, 'saver/cnn', global_step=step)\n",
    "                    print('checkpoint saved')\n",
    "\n",
    "    def reconstruct(self):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        def weights_to_grid(weights, rows, cols):\n",
    "            \"\"\"convert the weights tensor into a grid for visualization\"\"\"\n",
    "            height, width, in_channel, out_channel = weights.shape\n",
    "            padded = np.pad(weights, [(1, 1), (1, 1), (0, 0), (0, rows * cols - out_channel)],\n",
    "                            mode='constant', constant_values=0)\n",
    "            transposed = padded.transpose((3, 1, 0, 2))\n",
    "            reshaped = transposed.reshape((rows, -1))\n",
    "            grid_rows = [row.reshape((-1, height + 2, in_channel)).transpose((1, 0, 2)) for row in reshaped]\n",
    "            grid = np.concatenate(grid_rows, axis=0)\n",
    "\n",
    "            return grid.squeeze()\n",
    "\n",
    "        mnist = MNIST()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver, global_step = Model.continue_previous_session(sess, ckpt_file='saver/checkpoint')\n",
    "\n",
    "            # visualize weights\n",
    "            first_layer_weights = tf.get_default_graph().get_tensor_by_name(\"conv_1/kernel:0\").eval()\n",
    "            grid_image = weights_to_grid(first_layer_weights, 4, 8)\n",
    "\n",
    "            fig, ax0 = plt.subplots(ncols=1, figsize=(8, 4))\n",
    "            ax0.imshow(grid_image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax0.set_title('first conv layers weights')\n",
    "            plt.show()\n",
    "\n",
    "            # visualize results\n",
    "            batch_size = 36\n",
    "            x, y = mnist.get_batch(batch_size, dataset='testing')\n",
    "            org, recon = sess.run((self.x, self.reconstruction), feed_dict={self.x: x})\n",
    "\n",
    "            input_images = weights_to_grid(org.transpose((1, 2, 3, 0)), 6, 6)\n",
    "            recon_images = weights_to_grid(recon.transpose((1, 2, 3, 0)), 6, 6)\n",
    "\n",
    "            fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "            ax0.imshow(input_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax0.set_title('input images')\n",
    "            ax1.imshow(recon_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax1.set_title('reconstructed images')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T06:56:21.766966Z",
     "start_time": "2019-12-03T06:55:02.005147Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_autoencoder = ConvolutionalAutoencoder()\n",
    "conv_autoencoder.train(batch_size=100, passes=5000, new_training=True)\n",
    "conv_autoencoder.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
