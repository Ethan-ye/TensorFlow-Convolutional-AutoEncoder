{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:32:11.305710Z",
     "start_time": "2019-12-03T14:32:11.297779Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "from models import *\n",
    "from mnist import MNIST  # this is the MNIST data manager that provides training/testing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:01:40.864007Z",
     "start_time": "2019-12-03T15:01:40.818124Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(object):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        build the graph\n",
    "        \"\"\"\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # place holder of input data\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])  # [#batch, img_height, img_width, #channels]\n",
    "\n",
    "        # encode\n",
    "        conv1 = Convolution2D([5, 5, 1, 32], activation=tf.nn.relu, scope='conv_1')(x)\n",
    "        pool1 = MaxPooling(kernel_shape=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', scope='pool_1')(conv1)\n",
    "        conv2 = Convolution2D([5, 5, 32, 32], activation=tf.nn.relu, scope='conv_2')(pool1)\n",
    "        pool2 = MaxPooling(kernel_shape=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', scope='pool_2')(conv2)\n",
    "        unfold = Unfold(scope='unfold')(pool2)\n",
    "        encoded = FullyConnected(20, activation=tf.nn.relu, scope='encode')(unfold)\n",
    "        # decode\n",
    "        decoded = FullyConnected(7*7*32, activation=tf.nn.relu, scope='decode')(encoded)\n",
    "        fold = Fold([-1, 7, 7, 32], scope='fold')(decoded)\n",
    "        unpool1 = UnPooling((2, 2), output_shape=tf.shape(conv2), scope='unpool_1')(fold)\n",
    "        deconv1 = DeConvolution2D([5, 5, 32, 32], output_shape=tf.shape(pool1), activation=tf.nn.relu, scope='deconv_1')(unpool1)\n",
    "        unpool2 = UnPooling((2, 2), output_shape=tf.shape(conv1), scope='unpool_2')(deconv1)\n",
    "        reconstruction = DeConvolution2D([5, 5, 1, 32], output_shape=tf.shape(x), activation=tf.nn.sigmoid, scope='deconv_2')(unpool2)\n",
    "        # loss function\n",
    "        loss = tf.nn.l2_loss(x - reconstruction)  # L2 loss\n",
    "\n",
    "        # training\n",
    "        training = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "        #\n",
    "        self.x = x\n",
    "        self.reconstruction = reconstruction\n",
    "        self.loss = loss\n",
    "        self.training = training\n",
    "        self.encoded = encoded\n",
    "\n",
    "    def train(self, batch_size, passes, new_training=True):\n",
    "        \"\"\"\n",
    "\n",
    "        :param batch_size:\n",
    "        :param passes:\n",
    "        :param new_training:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mnist = MNIST()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # prepare session\n",
    "            if new_training:\n",
    "                saver, global_step = Model.start_new_session(sess)\n",
    "            else:\n",
    "                saver, global_step = Model.continue_previous_session(sess, ckpt_file='saver/checkpoint')\n",
    "\n",
    "            # start training\n",
    "            for step in range(1+global_step, 1+passes+global_step):\n",
    "                x, y = mnist.get_batch(batch_size)\n",
    "                self.training.run(feed_dict={self.x: x})\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    loss = self.loss.eval(feed_dict={self.x: x})\n",
    "                    print(\"pass {}, training loss {}\".format(step, loss))\n",
    "\n",
    "                if step % 1000 == 0:  # save weights\n",
    "                    saver.save(sess, 'saver/cnn', global_step=step)\n",
    "                    print('checkpoint saved')\n",
    "\n",
    "    def reconstruct(self):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        def weights_to_grid(weights, rows, cols):\n",
    "            \"\"\"convert the weights tensor into a grid for visualization\"\"\"\n",
    "            height, width, in_channel, out_channel = weights.shape\n",
    "            padded = np.pad(weights, [(1, 1), (1, 1), (0, 0), (0, rows * cols - out_channel)],\n",
    "                            mode='constant', constant_values=0)\n",
    "            transposed = padded.transpose((3, 1, 0, 2))\n",
    "            reshaped = transposed.reshape((rows, -1))\n",
    "            grid_rows = [row.reshape((-1, height + 2, in_channel)).transpose((1, 0, 2)) for row in reshaped]\n",
    "            grid = np.concatenate(grid_rows, axis=0)\n",
    "\n",
    "            return grid.squeeze()\n",
    "\n",
    "        mnist = MNIST()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver, global_step = Model.continue_previous_session(sess, ckpt_file='saver/checkpoint')\n",
    "\n",
    "            # visualize weights\n",
    "            first_layer_weights = tf.get_default_graph().get_tensor_by_name(\"conv_1/kernel:0\").eval()\n",
    "            grid_image = weights_to_grid(first_layer_weights, 4, 8)\n",
    "\n",
    "            fig, ax0 = plt.subplots(ncols=1, figsize=(8, 4))\n",
    "            ax0.imshow(grid_image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax0.set_title('first conv layers weights')\n",
    "            plt.show()\n",
    "\n",
    "            # visualize results\n",
    "            batch_size = 36\n",
    "            x, y = mnist.get_batch(batch_size, dataset='testing')\n",
    "            org, recon = sess.run((self.x, self.reconstruction), feed_dict={self.x: x})\n",
    "\n",
    "            input_images = weights_to_grid(org.transpose((1, 2, 3, 0)), 6, 6)\n",
    "            recon_images = weights_to_grid(recon.transpose((1, 2, 3, 0)), 6, 6)\n",
    "\n",
    "            fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "            ax0.imshow(input_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax0.set_title('input images')\n",
    "            ax1.imshow(recon_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "            ax1.set_title('reconstructed images')\n",
    "            plt.show()\n",
    "            \n",
    "    def encode(self):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "#         def weights_to_grid(weights, rows, cols):\n",
    "#             \"\"\"convert the weights tensor into a grid for visualization\"\"\"\n",
    "#             height, width, in_channel, out_channel = weights.shape\n",
    "#             padded = np.pad(weights, [(1, 1), (1, 1), (0, 0), (0, rows * cols - out_channel)],\n",
    "#                             mode='constant', constant_values=0)\n",
    "#             transposed = padded.transpose((3, 1, 0, 2))\n",
    "#             reshaped = transposed.reshape((rows, -1))\n",
    "#             grid_rows = [row.reshape((-1, height + 2, in_channel)).transpose((1, 0, 2)) for row in reshaped]\n",
    "#             grid = np.concatenate(grid_rows, axis=0)\n",
    "\n",
    "#             return grid.squeeze()\n",
    "\n",
    "        mnist = MNIST()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            saver, global_step = Model.continue_previous_session(sess, ckpt_file='saver/checkpoint')\n",
    "\n",
    "#             # visualize weights\n",
    "#             first_layer_weights = tf.get_default_graph().get_tensor_by_name(\"conv_1/kernel:0\").eval()\n",
    "#             grid_image = weights_to_grid(first_layer_weights, 4, 8)\n",
    "\n",
    "#             fig, ax0 = plt.subplots(ncols=1, figsize=(8, 4))\n",
    "#             ax0.imshow(grid_image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "#             ax0.set_title('first conv layers weights')\n",
    "#             plt.show()\n",
    "\n",
    "            # visualize results\n",
    "            codes = np.empty([50000,20], dtype = np.float32)\n",
    "            labels = np.empty([50000,1], dtype = np.int)\n",
    "            batch_size = 100\n",
    "            start = time.time()\n",
    "            for i in range(500):\n",
    "                x, y = mnist.get_batch(batch_size, dataset='training')\n",
    "                codes[i*batch_size:(i+1)*batch_size,] = sess.run((self.encoded), feed_dict={self.x: x}) \n",
    "                labels[i*batch_size:(i+1)*batch_size,] = y@(np.arange(10).reshape(10,1))\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print('encoded:%d, %f sec' % ((i+1)*batch_size, time.time() - start))\n",
    "                \n",
    "            return codes,labels\n",
    "#             batch_size = 10000\n",
    "#             x, y = mnist.get_batch(batch_size, dataset='testing')\n",
    "#             org, recon = sess.run((self.x, self.reconstruction), feed_dict={self.x: x})\n",
    "\n",
    "#             input_images = weights_to_grid(org.transpose((1, 2, 3, 0)), 6, 6)\n",
    "#             recon_images = weights_to_grid(recon.transpose((1, 2, 3, 0)), 6, 6)\n",
    "\n",
    "#             fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "#             ax0.imshow(input_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "#             ax0.set_title('input images')\n",
    "#             ax1.imshow(recon_images, cmap=plt.cm.gray, interpolation='nearest')\n",
    "#             ax1.set_title('reconstructed images')\n",
    "#             plt.show()\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:01:43.584269Z",
     "start_time": "2019-12-03T15:01:42.890589Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_autoencoder = ConvolutionalAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_autoencoder.train(batch_size=100, passes=20, new_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T14:22:00.765805Z",
     "start_time": "2019-12-03T14:21:50.872775Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_autoencoder.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:02:20.647584Z",
     "start_time": "2019-12-03T15:01:51.458990Z"
    }
   },
   "outputs": [],
   "source": [
    "codes,labels = conv_autoencoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:02:24.016540Z",
     "start_time": "2019-12-03T15:02:24.011553Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA_2D = PCA(n_components=2)#2主成分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:02:25.786087Z",
     "start_time": "2019-12-03T15:02:25.696365Z"
    }
   },
   "outputs": [],
   "source": [
    "minist_2D = PCA_2D.fit_transform(codes)#投影到2主成分空间\n",
    "minist_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:04:56.221787Z",
     "start_time": "2019-12-03T15:04:53.610145Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cax = ax.scatter(minist_2D[0:50000,0], minist_2D[0:50000,1], c=labels[0:50000,0], alpha=0.5)# \n",
    "fig.colorbar(cax)\n",
    "ax.set_xlabel(r'$\\Delta_i$', fontsize=15)\n",
    "ax.set_ylabel(r'$\\Delta_{i+1}$', fontsize=15)\n",
    "ax.set_title('Volume and percent change')\n",
    "\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T15:52:40.745660Z",
     "start_time": "2019-12-03T15:12:24.515295Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(learning_rate=100, n_components=2, random_state=0, perplexity=5)\n",
    "tsne5 = model.fit_transform(codes)\n",
    "print('tsne5 finish')\n",
    "\n",
    "model = TSNE(learning_rate=100, n_components=2, random_state=0, perplexity=30)\n",
    "tsne30 = model.fit_transform(codes)\n",
    "print('tsne30 finish')\n",
    "\n",
    "model = TSNE(learning_rate=100, n_components=2, random_state=0, perplexity=50)\n",
    "tsne50 = model.fit_transform(codes)\n",
    "print('tsne50 finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T23:55:37.411267Z",
     "start_time": "2019-12-03T23:55:33.568501Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "plt.scatter(tsne5[:, 0], tsne5[:, 1], c=labels[:,0], alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(tsne30[:, 0], tsne30[:, 1], c=labels[:,0], alpha=0.5)\n",
    "\n",
    "# plt.subplot(313)\n",
    "# plt.scatter(tsne50[:, 0], tsne50[:, 1], c=labels[:,0], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
